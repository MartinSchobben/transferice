---
title: "model-types"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{model-types}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(transferice)
```




# Data

For a starters we use again all dinocyst data but exclusively use temperature at a 30 meter water depth as an outcome variable.

```{r lme}
fm <- as.formula(
  paste("t_an + p_an + n_an + i_an + o_an + s_an + I_an ~ .")
)
```

```{r pcs}

# recipe
rcp <- recipes::recipe(fm, data = dinodat) |> 
  # update roles
  recipes::update_role(longitude, latitude, new_role = "spatial") |> 
  recipes::update_role(.data$hole_id, new_role = "group id") |>
  recipes::update_role(.data$sample_id, new_role = "id") |> 
  # rename taxa
  recipes::step_rename_at(recipes::all_predictors(), fn = ~ paste0("taxa_", .)) |> 
  # rescale outcomes
  recipes::step_nzv(recipes::all_outcomes()) |> 
  recipes::step_normalize(recipes::all_outcomes()) |> 
  # rescale predictor
  recipes::step_logit(recipes::all_predictors(), offset = 0.025) |> 
  # reduce dimensions
  recipes::step_pca(recipes::all_predictors(), num_comp = 9) |> 
  # pivot for multilevel
  step_pivot(recipes::all_outcomes(), options = list(names_to = "parameter"))
  

cast <- recipes::prep(rcp, training = dinodat) |> 
  # apply to training data
  recipes::bake(new_data = NULL)
```


```{r}

library(nlme)

lme_spec <- parsnip::linear_reg() |> 
  parsnip::set_engine("lme", ~PC1 + PC2|parameter)

lme_fit <- lme_spec |> 
 parsnip::fit(value~PC1 + PC2, data = cast)
  
```


```{r plot}

ggplot(cast, aes(value, PC2, color = parameter)) + geom_point()
```

# spatial variance

```{r spat}
# recipe
rcp <- recipes::recipe(fm, data = dinodat) |> 
  # update roles
  recipes::update_role(longitude, latitude, new_role = "spatial") |> 
  recipes::update_role(.data$hole_id, new_role = "group id") |>
  recipes::update_role(.data$sample_id, new_role = "id") |> 
  # rename taxa
  recipes::step_rename_at(recipes::all_predictors(), fn = ~ paste0("taxa_", .)) |> 
  # remove zero distance
  step_zerogeodist(lon = longitude, lat = latitude) |> 
  # rescale outcomes
  # recipes::step_nzv(recipes::all_outcomes()) |> 
  recipes::step_normalize(recipes::all_outcomes()) |> 
  # rescale predictor
  recipes::step_logit(recipes::all_predictors(), offset = 0.025) |> 
  # reduce dimensions
  recipes::step_pca(recipes::all_predictors(), num_comp = 9) |> 
  # pivot for multilevel
  step_pivot(recipes::all_outcomes(), options = list(names_to = "parameter"))
    

cast <- recipes::prep(rcp, training = dinodat) |> 
  # apply to training data
  recipes::bake(new_data = NULL)

lme_spec <- parsnip::linear_reg() |> 
  parsnip::set_engine(
    "lme", 
    random = ~PC1 + PC2|parameter, 
    correlation = corSpatial(form = ~longitude + latitude|parameter, type = "g" )
  )

lme_fit <- lme_spec |> 
 parsnip::fit(value~PC1 + PC2, data = cast)

```